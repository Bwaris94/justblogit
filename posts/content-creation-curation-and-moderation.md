> :Hero src=https://source.unsplash.com/7Equ1tUYmps/1900x600,
>       mode=light,
>       target=desktop,
>       leak=320px

> :Hero src=https://source.unsplash.com/7Equ1tUYmps/1200x600,
>       mode=light,
>       target=mobile,
>       leak=96px

> :Hero src=https://source.unsplash.com/7Equ1tUYmps/1900x600,
>       mode=dark,
>       target=desktop,
>       leak=320px

> :Hero src=https://source.unsplash.com/7Equ1tUYmps/1200x600,
>       mode=dark,
>       target=mobile,
>       leak=96px

> :Title shadow=0 0 8px white, color=white

Content creation, curation and moderation: ramblings of another founder trying to change the system and all that jazz

> :Author   name=Beenish Waris,
>           date=Wed March 02 2020,
>           avatar=https://pbs.twimg.com/profile_images/1140999958029590528/XLTQRvyz_400x400.jpg,
>           url=https://www.linkedin.com/in/beenish-waris-83abb5b1/          

<br>

# Content creation, curation and moderation: ramblings of another founder trying to change the system and all that jazz


Blogging and content created in the form of articles and newsletters has been overwhelming for readers in recent years. From tools like Acrolinx, Grammarly, Ahrefs and GPT-3 among a myriad of others for content creation, the spread of “optimised” content has increased over the last decade. Clickbaity headlines, keyword usage, number of words in an article have become factors, that our incentive systems seem to prioritise by featuring them in the first few results on google search. Combine this trend with the advent of new business models like Substack which enables people (literally anyone) to monetise what they are writing has resulted in domain specific editorial skills becoming almost redundant. 
This begs the question that considering these macro trends that enable more people to create content: how do we as individuals find the content, we want to consume from the monstrous amount of content that exists out there? Furthermore, what is the nature and quality of this content? 

Let’s start with looking at how much content actually exists. According to Forbes, in 2018, we created 2.5 quintillion bytes of data every day, and the majority of this data (90 per cent) has been created in the last two years alone (Forbes, 2018). Another mind-boggling statistic is that every second, on average, around 6,000 tweets are tweeted on Twitter which totals to over 350,000 tweets sent per minute, 500 million tweets per day and around 200 billion tweets per year. (Internet Live Stats, 2021) Another source suggests that there were 500 million blogs that exist in 2019 (Optinmonster, 2021). And blogs do not really contain other types of content that we read on Facebook, comments on posts among others or online publications like journals, magazines, newsletters etc. Suffice it to say: this is A LOT of content. What does this content do for us? 

There is now ample research that details the impact of overload of information and what exposure to digital technologies does. The problem is not inherent to digital technologies but rather within the ecosystem we have created where we have enabled content creation to be a seamless process that can be undertaken by anyone but have not put the same focus on curation. 

I recently came across an NPR talk from a decade ago, where a journalist describes his experience of going on a retreat with neuroscientists without any network coverage which meant they had no chance of going online. They reiterated the three-day effect: of not being exposed to digital technologies, content and their pertaining nudges. The journalist, Matt Richtel, used the analogy of food and nutrition to explain digital technologies. I want to extend this idea to that of content. There’s digital content that can be compared to Twinkies and content that can be compared to Brussel Sprouts meaning that one has long term positive impact neurologically and from the other you can derive short-term gratification with some harmful long-term consequences. And just like with food: if you over-consume, you face issues like obesity and pertaining illnesses. If you overconsume information or misinformation, you face the equivalent of that in neurological detriment (NPR, 2010).

While this clearly establishes the need for curation services, let us not forget that recommendation engines aim to do a little bit of this incentivized by monetising your attention and generating ad revenue. The issue, however, stems from the fact that we have somehow turned social media platforms into our primary news and knowledge acquisition channel. Again, this has both pros and cons: The Jasmine Revolution and the Egyptian revolution in 2011 as well as the recent George Floyd case that resulted in nationwide protests against racial injustice in the United States were all to a degree (some more than others) propelled by the availability of a camera on hand and the ability to reach a global audience with the content one had. Primary sources of content have increased in quantity since we now walk around with a small computer in our hands and connectivity that enables us to share in a matter of seconds. 

However, the downside is that often on social media we are interpreting primary or sometimes even secondary sources of information. Put this into a context where it is being done with a closed group of like-minded people and you will through no fault (or slight fault) of your own develop a staunch worldview based on this one interpretation. Now imagine being recommended similar content or content consumed by similar users. This is what collaborative filtering essentially does for content. Yes, by now you would probably have gone down a rabbit hole of this one-sided worldview. Think QAnon, storming of the Capitol Hill, anti-vaxxers and the list goes on (I clearly have a bias here but I could not think of any leftist groups: see my point exactly). 

Another issue is derived from the fact that most of the business models of these social media platforms are based on monetising attention: that is earn money by showing us advertisements we might or might not want to see. Which also has its pros and cons: wouldn’t you rather have personalised advertisements perhaps showing you a sale on a product you were actually looking to buy as opposed to something you did not even have on your radar? The issue arises when content is created solely for the purpose of selling as with content marketing. Not to demonise marketers here, content marketing can be an educational tool as well. But a balance needs to be struck. Since our incentive systems clearly prefer one type of content that is optimised one, we miss out on a lot of quality content. Just ask yourself: how often have you even looked at results on the second page of a google search? 

But propagating moderation and curation is one thing. Who should be responsible for it is another, more complex question, that can have several negative consequences in itself? For instance, MIT Technology Review claims that users not tech executives should have the power to decide what the content on social media platforms like Facebook and Twitter should be. The premise of the argument stems from the sentiment of democratizing it. But wouldn’t a mechanism of having all users decide on the type of content displayed lead to more fake news spreading like wildfire? 

Let’s not forget that social networks of people serve a different aim than content platforms. Platforms like Facebook and Twitter have blurred the lines between content moderation and virtual socialisation. They enable interpretation of real-world events through comic relief, commentary, satire and other mechanisms available to different users. Empowering users with a voice sounds good in theoretically one thing but what we need is a weighted mechanism that prefers domain expertise a bit more than an opinion of a citizen. To be fair, determining domain expertise in this hyper digital time is not an easy feat. However, one way to go about it is how Ray Dalio describes assessing the believability of a person on a certain matter: they have successfully done the task they claim to be “experts” on at least three times and they have coherent cause-effect explanations that lead them to their conclusions. This segmentation of users when moderating for content in essential. 

Tech-executives being able to make calls on moderation certainly does not help. Jack Dorsey banning Donald Trump (a welcome action but not a welcome established mechanism) should certainly not become a norm. Think about it: is it productive that tech executives can decide who to censor on a whim or a heated controversial event like the recent Capitol storming? Let us not forget that Facebook and Twitter have constantly moderated content of despots (Myanmar General and top military leaders banned by Facebook, Hezbollah banned although they hold seats in Lebanon Parliament), given more power to elected officials than they have to normal users and have made governance policies about what content should be allowed on the platform and what not. 

This power accumulated into a few big corporations without governance and regulation is a trap that could prove disastrous for our digital society. Australian Government in it’s recent attempt to have Facebook and Google pay media establishments is a step but does it not essentially empower a few traditional media corporations like Rupert Murdoch's media conglomerate on top of these two tech companies? Shouldn’t the aim be to create a market that is easier to enter for smaller, independent players? These are questions that we as a society need to think about through predictive and proactive reasoning. Build scenarios of a society with an embedded technology and think about multiple futures that we can create with the technology in question, pick one and strive to build it. Isolated and reactive policy making in this arena can cause more polarization and so more harm than good. 
As for curation, to be effective we need to have a hybrid system with automated collection and algorithmic curation with a human domain expert. We also need to develop thematically specialised platforms. Curation mechanisms and factors differ across fields. Measuring the quality of a blog article on programming requires different expertise than measuring quality of a fashion article. Not only that: there is obviously a subjective element to determining quality, for instance, motivation for consuming that particular piece. Learning pieces for instance, would fundamentally differ from experiential pieces. Purposes of reading differ across fields too as does frequency of consumed articles. 

In short, my MVP formula of curation would look like this: 

Domain expert’s assessment + Reader assessment + Categorization of article (purpose) + semantics + incentives to write quality articles to share knowledge = content that would equate to Brussel Sprouts. 

P.S. Yes, yes, I am critiquing the very system that is allowing me to write this article. The irony of it is not lost on me 😉 


---